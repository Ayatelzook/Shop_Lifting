# üõí Shoplifting Detection Using Deep Learning

This project focuses on detecting shoplifting activities using video data. The goal is to create a system that processes video frames, applies deep learning models, and predicts whether shoplifting is occurring. The project explores different deep learning approaches to improve the accuracy and efficiency of shoplifting detection.

## üìå Project Overview

### **Purpose**  
The project involves the following key steps:  
1. **Data Preprocessing** ‚Äì Preparing video frames for input to the model.  
2. **Modeling** ‚Äì Implementing different deep learning architectures to detect shoplifting.  
3. **Training** ‚Äì Training the models on the preprocessed video data.  
4. **Evaluation** ‚Äì Assessing the models‚Äô performance using accuracy, precision, and recall.  
5. **Prediction** ‚Äì Creating a pipeline for real-time shoplifting detection on new video data.  

---

## üìÇ Project Structure

---

## üé• Data  

### **Input Data**  
The dataset consists of video files in MP4 format, categorized into two classes:  
- **Shoplifting** ‚Äì Videos showing shoplifting activities.  
- **Non-shoplifting** ‚Äì Videos showing normal shopping behavior.  

### **Data Preprocessing**  
The preprocessing steps include:  
- **Frame Extraction** ‚Äì Videos are converted into frames at a fixed frame rate.  
- **Padding and Normalization** ‚Äì  
    - Videos are padded to max frames if they are shorter.  
    - Pixel values are normalized to the range `[0, 1]`.  
- **Resizing** ‚Äì Frames are resized to a fixed resolution for consistent input size.  

---

## üèÜ Models  

### **1. I3D Model (Inflated 3D Convolutional Neural Network)**  
The I3D model is designed to capture spatiotemporal patterns in video data. It expands 2D convolutional layers into 3D to process video sequences more effectively.  

#### **Architecture**  
- **3D Convolutional Layers** ‚Äì Extract spatiotemporal features from video frames.  
- **Batch Normalization** ‚Äì Normalizes activations to improve convergence.  
- **Global Average Pooling** ‚Äì Reduces dimensionality while retaining important information.  
- **Fully Connected Layers** ‚Äì Dense layers for final classification.  
- **Sigmoid Activation** ‚Äì Outputs a binary prediction (shoplifting or not).  

#### **Highlights**  
‚úÖ Strong spatiotemporal learning through 3D convolutions.  
‚úÖ Effective for capturing complex video patterns.  

#### **Training**  
- Optimizer: Adam  
- Loss: Binary Cross-Entropy  
- Metrics: Accuracy, Precision, Recall  

---

### **2. CNN + Bidirectional LSTM Model**  
This model combines convolutional layers for spatial feature extraction and a BiLSTM layer for temporal feature learning.  

#### **Architecture**  
- **TimeDistributed CNN Layers** ‚Äì Applies convolution to each frame individually.  
- **Batch Normalization and MaxPooling** ‚Äì Improves learning efficiency.  
- **Global Average Pooling** ‚Äì Reduces dimensionality.  
- **Bidirectional LSTM** ‚Äì Captures sequential patterns and improves temporal understanding.  
- **Dense Layers** ‚Äì Final classification layers with dropout for regularization.  

#### **Highlights**  
‚úÖ Combines spatial and temporal learning.  
‚úÖ BiLSTM captures long-range dependencies between frames.  

#### **Training**  
- Optimizer: Adam (learning rate = 0.0001)  
- Loss: Binary Cross-Entropy  
- Metrics: Accuracy, Recall  

---

### **3. Hybrid 3D CNN + LSTM Model**  
This model combines 3D convolutional layers for spatiotemporal feature extraction and LSTM layers for temporal learning.  

#### **Architecture**  
- **3D Convolutional Layers** ‚Äì Extracts spatiotemporal patterns.  
- **Batch Normalization** ‚Äì Normalizes activations to stabilize training.  
- **MaxPooling** ‚Äì Reduces the spatial dimensions.  
- **TimeDistributed Flattening** ‚Äì Preserves temporal features across frames.  
- **LSTM Layer** ‚Äì Learns long-term dependencies between frames.  
- **Dense Layers** ‚Äì Fully connected layers for classification.  
- **Softmax Activation** ‚Äì Outputs class probabilities.  

#### **Highlights**  
‚úÖ Effective combination of 3D CNN and LSTM for complex spatiotemporal learning.  
‚úÖ Softmax activation for multi-class classification.  

#### **Training**  
- Optimizer: Adam (learning rate = LEARNING_RATE)  
- Loss: Sparse Categorical Cross-Entropy  
- Metrics: Accuracy  

---

## üìä Evaluation  

### **Metrics**  
The models are evaluated using the following metrics:  
- **Accuracy** ‚Äì Measures overall prediction correctness.  
- **Precision** ‚Äì Measures the proportion of correctly predicted shoplifting cases.  
- **Recall** ‚Äì Measures the proportion of actual shoplifting cases that were correctly predicted.  
- **F1-Score** ‚Äì Harmonic mean of Precision and Recall.  

### **Performance Comparison**  
| Model | Accuracy | Precision | Recall | F1-Score |  
|-------|----------|-----------|--------|----------|  
| I3D Model | TBD | TBD | TBD | TBD |  
| CNN + BiLSTM | TBD | TBD | TBD | TBD |  
| Hybrid 3D CNN + LSTM | TBD | TBD | TBD | TBD |  

---

## üöÄ Prediction Pipeline  

### **Pipeline Overview**  
The prediction pipeline involves the following steps:  
1. **Load Model** ‚Äì Load the trained model.  
2. **Extract Frames** ‚Äì Convert the input video into frames.  
3. **Preprocess Frames** ‚Äì Resize, pad, and normalize the frames.  
4. **Predict** ‚Äì Pass the frames through the model for prediction.  
5. **Output** ‚Äì Return the classification result (shoplifting or not).  

---

## üìå Usage  

### **Prepare the Data**  
1. Place the video files in the `data/` directory.  
2. Run the preprocessing script to extract frames and normalize them.  

### **Train the Model**  
1. Load the training script.  
2. Adjust the hyperparameters if needed.  
3. Start training and monitor the performance.  

### **Evaluate the Model**  
1. Run the evaluation script.  
2. Review the output metrics (accuracy, precision, recall).  

### **Run Predictions**  
1. Load the trained model.  
2. Pass the video file to the prediction script.  
3. Get the output prediction.  

---

## ‚úÖ Conclusion  
This project demonstrates how deep learning models, including I3D, CNN + BiLSTM, and Hybrid 3D CNN + LSTM, can be used to detect shoplifting activities from video data. By combining spatiotemporal feature extraction and sequential learning, the models achieve high accuracy in identifying suspicious activities.  

---

## üìé Acknowledgments  
- TensorFlow  
- Keras  
- OpenCV  
